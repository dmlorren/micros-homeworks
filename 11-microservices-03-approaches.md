# Домашнее задание к занятию «Микросервисы: подходы» - Иванов Дмитрий (fops-13)

Вы работаете в крупной компании, которая строит систему на основе микросервисной архитектуры.
Вам как DevOps-специалисту необходимо выдвинуть предложение по организации инфраструктуры для разработки и эксплуатации.


## Задача 1: Обеспечить разработку

Предложите решение для обеспечения процесса разработки: хранение исходного кода, непрерывная интеграция и непрерывная поставка. 
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- облачная система;
- система контроля версий Git;
- репозиторий на каждый сервис;
- запуск сборки по событию из системы контроля версий;
- запуск сборки по кнопке с указанием параметров;
- возможность привязать настройки к каждой сборке;
- возможность создания шаблонов для различных конфигураций сборок;
- возможность безопасного хранения секретных данных (пароли, ключи доступа);
- несколько конфигураций для сборки из одного репозитория;
- кастомные шаги при сборке;
- собственные докер-образы для сборки проектов;
- возможность развернуть агентов сборки на собственных серверах;
- возможность параллельного запуска нескольких сборок;
- возможность параллельного запуска тестов.

Обоснуйте свой выбор.


### Ответ:
```
1. Использовать облачная платформы:
   - Как ЯндексCloud, Selectel, Digital Ocean (за рубежом AWS или Google Cloud Platform), для размещения инфраструктуры.

2. Использовать контроль версий:
   - Использовать Git в качестве системы контроля версий, где каждый сервис будет иметь свой собственный репозиторий. Варианты: GitHub, GitLab или Bitbucket для хостинга репозиториев.

3. Внедрить непрерывную интеграцию и доставку (CI/CD):
   - Интегрировать систему CI/CD, такую как Jenkins, GitLab CI/CD или CircleCI. Это позволит автоматически запускать сборки при определенных событиях:
     - Запуск сборки по событию из системы контроля версий: Сборка будет запускаться при коммите или пулл-запросе в репозитории.
     - Запуск сборки по кнопке: В интерфейсе CI/CD системы можно добавить кнопку для ручной сборки с возможностью указания параметров.

4. Настраивать сборки:
   - Позволить привязывать настройки к каждой сборке, включая использование параметров и переменных окружения. Это можно реализовать с помощью конфигурационных файлов, которые хранятся в каждом репозитории.

5. Использовать шаблоны для конфигураций:
   - Создание шаблонов конфигураций сборок в CI/CD системе для различных типов сборок. Например, различные конфигурации для тестирования, продакшн-среды и т.д.

6. Безопасное хранение секретных данных:
   - Использование инструментов, таких как HashiCorp Vault или встроенные решения (например, Secrets в GitLab CI) для безопасного хранения паролей и ключей доступа.

7. Несколько конфигураций для сборки:
   - Реализовать возможность создавать разные конфигурации сборок из одного репозитория, применяя разные параметры и окружения.

8. Применять кастомные шаги:
   - CI/CD система должна поддерживать возможность создания кастомных шагов при сборке с использованием скриптов или плагинов.

9. Собственные Docker-образы:
   - Использовать Docker для создания собственных образов, необходимых для сборок проектов. Это позволит обеспечить единообразие окружений.

10. Агенты сборки:
    - Реализовать возможность разворачивать агентов сборки на собственных серверах, используя Docker или Kubernetes для управления микросервисами и эффективного распределения ресурсов.

11. Параллельный запуск сборок:
    - CI/CD система должна поддерживать возможность параллельного запуска нескольких сборок для разных микросервисов, что ускорит процесс разработки.

12. Параллельный запуск тестов:
    - Настроить параллельное выполнение тестов, используя фреймворки, такие как JUnit или pytest, и разделить тесты на несколько потоков для экономии времени.
```



## Задача 2: Логи

Предложите решение для обеспечения сбора и анализа логов сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор логов в центральное хранилище со всех хостов, обслуживающих систему;
- минимальные требования к приложениям, сбор логов из stdout;
- гарантированная доставка логов до центрального хранилища;
- обеспечение поиска и фильтрации по записям логов;
- обеспечение пользовательского интерфейса с возможностью предоставления доступа разработчикам для поиска по записям логов;
- возможность дать ссылку на сохранённый поиск по записям логов.

Обоснуйте свой выбор.


### Ответ:

Краткая суть - собираем и передаём логи, организовываем их хранение и для удобства их просмотра и анализа используем kibana.

Подробная схема взаимодействия:
```
1. Организация сбора логов:
- Плюсы: Низкие требования к приложениям (логирование в stdout).
- Инструмент: Fluent Bit или Filebeat — агенты, которые запускаются на каждом хосте и собирают логи из stdout (или файлов). Они поддерживают различные форматы и могут объединяться с другими сервисами.

2. Организация передачи логов:
- Инструмент: Fluentd или Logstash (часть стека ELK) могут использоваться для передачи логов от агентских компонентов к центральному хранилищу. Эти компоненты гарантируют доставку логов через механизмы, такие как:
  - Bufferring: лог-сообщения временно сохраняются в памяти или на диске при сбоях в процессе передачи.
  - Retries: несколько попыток отправки в случае неудачи.
  
3. Организация хранение логов:
- Инструмент: Elasticsearch — это быстрое, масштабируемое хранилище, которое обеспечивает возможность поиска и фильтрации по записям логов. Записи могут храниться в индексах, что позволяет эффективно выполнять запросы.

4. Реализация анализа и визуализации:
- Инструмент: Kibana — веб-интерфейс для визуализации и поиска в логах, который интегрируется с Elasticsearch. Kibana позволяет разработчикам:
  - Выполнять поиск по логам, используя гибкие запросы.
  - Создавать дашборды и визуализации.
  - Предоставлять доступ различным пользователям, используя механизмы управления доступом.

### Принципы взаимодействия компонентов
1. Сбор логов: Агент Fluent Bit/Filebeat собирает логи из stdout всех микросервисов, работающих на хостах.
2. Передача логов: Логи передаются на Fluentd/Logstash, которые обрабатывают данные (например, добавляют теги, конвертируют форматы) и отправляют их в Elasticsearch.
3. Хранение логов: Elasticsearch получает данные и индексирует их для обеспечения быстрой фильтрации и поиска.
4. Анализ и интерфейс: Разработчики используют Kibana для выполнения запросов к Elasticsearch, просмотра и анализа логов, создания дашбордов. Также возможна генерация прямых ссылок на сохраненные поисковые запросы для удобства доступа.

### Схема работы
[Микросервисы] --> [Fluent Bit/Filebeat] --> [Fluentd/Logstash] --> [Elasticsearch] --> [Kibana]
```

## Задача 3: Мониторинг

Предложите решение для обеспечения сбора и анализа состояния хостов и сервисов в микросервисной архитектуре.
Решение может состоять из одного или нескольких программных продуктов и должно описывать способы и принципы их взаимодействия.

Решение должно соответствовать следующим требованиям:
- сбор метрик со всех хостов, обслуживающих систему;
- сбор метрик состояния ресурсов хостов: CPU, RAM, HDD, Network;
- сбор метрик потребляемых ресурсов для каждого сервиса: CPU, RAM, HDD, Network;
- сбор метрик, специфичных для каждого сервиса;
- пользовательский интерфейс с возможностью делать запросы и агрегировать информацию;
- пользовательский интерфейс с возможностью настраивать различные панели для отслеживания состояния системы.

Обоснуйте свой выбор.


### Ответ:

Краткая суть - через нод экспортер снимаем необходимые метрики, а через прометэюс их снимаем и храним, с помощью графаны (натравленной на прометеюс) их визуализируем через дашборды, графики и тд.


```
1. Сбор метрик
- Инструменты: Prometheus и Node Exporter.
  - Node Exporter: этот инструмент устанавливается на каждом хосте и обеспечивает мониторинг системных метрик, таких как загрузка CPU, использование RAM, дискового пространства (HDD), сетевых интерфейсов и т.д.
  - Prometheus: является системой мониторинга и алертинга, которая собирает метрики с Node Exporter и других приложений (с помощью экспортеров или API). Prometheus может быть настроен для сбора метрик с сервисов (специфичных метрик) с использованием библиотеки Prometheus Client, интегрированной в каждое приложение.

2. Хранение метрик
- Prometheus: обеспечивает долговременное хранение метрик с возможностью быстро выполнять запросы.

3. Визуализация и пользовательский интерфейс
- Grafana: мощный инструмент для визуализации данных, который может интегрироваться с Prometheus как источником данных. Grafana позволяет создавать настраиваемые панели для отображения метрик, а также поддерживает множество графиков и дашбордов для мониторинга состояния системы.

### Принципы взаимодействия компонентов
1. Сбор метрик с хостов: Node Exporter запускается на каждом сервере, собирает данные о состоянии ресурсов и передает их Prometheus.
2. Сбор метрик сервисов: Приложения могут использовать клиентские библиотеки Prometheus для отчета о специфичных метриках и отправлять их Prometheus.
3. Хранение и обработка: Prometheus периодически опрашивает Node Exporter и приложения на предмет новых метрик, которые затем хранятся в локальной базе данных.
4. Анализ и визуализация: Grafana запрашивает данные из Prometheus и предоставляет интерфейс для построения дашбордов, а также возможность настройки пользовательских запросов для агрегации информации.

### Схема работы
[Хосты + Node Exporter] <--> [Prometheus] <--> [Grafana]
                   |
                   +--> [Сервисы с метриками]

### Дополнительные возможности
- Алерты и уведомления: Prometheus поддерживает систему алертинга, которая может быть настроена для уведомления команды о нарушениях в состоянии системы или сервисов.
- Интеграция с другими системами: графики и данные из Grafana могут быть интегрированы с другими системами мониторинга или мессенджерами для оповещения о критических состояниях.
- Масштабируемость: Prometheus может быть легко развернут в кластерной инфраструктуре, что позволяет масштабировать решение по мере увеличения объемов данных
```

---
